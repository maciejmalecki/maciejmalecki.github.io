<!DOCTYPE html>
<html>

<head>
	
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-8E02V5EDF9"></script>
	<script>
		var useCookies = (localStorage.getItem('useCookies') === 'true');
		if (useCookies) {
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());
			gtag('config', 'G-8E02V5EDF9', { 'anonymize_ip': true });
		}
	</script>
	

	<!-- Meta -->
	<meta charset="UTF-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
	<meta name="generator" content="Jekyll">

	<title>The Rise of Vibe Coding</title>
  <meta name="description" content="t.b.d.">

	<!-- CSS & fonts -->
	<link rel="stylesheet" href="/css/main.css">

	<!-- RSS -->
	<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="ATOM Feed" />

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/png" href="img/favicon.png">

</head>


<body>
	<div id="wrap">

	  	<!-- Navigation -->
	  	<nav id="nav">
	<div id="nav-list">
		<a href="//">Home</a>

		<!-- Nav pages -->
	  
	    
	  
	    
	      <a href="/about" title="About">About</a>
	    
	  
	    
	      <a href="/architecture" title="Architecture">Architecture</a>
	    
	  
	    
	      <a href="/asm" title="Assembly language">Assembly language</a>
	    
	  
	    
	  
	    
	      <a href="/cbm" title="8bits">8bits</a>
	    
	  
	    
	      <a href="/genai" title="GenAI">GenAI</a>
	    
	  
	    
	  
	    
	  
	    
	      <a href="/privacy" title="Privacy">Privacy</a>
	    
	  
	    
	      <a href="/sh" title="IoT">IoT</a>
	    
	  
	    
	  
	    
	  
	    
	  
    
    <!-- Nav links -->
	  <a href="https://github.com/maciejmalecki">Github</a>


	</div>
  
  <!-- Nav footer -->
	
	  <footer>
	
	<span>version 1.0.0</span>

</footer>
	

</nav>


    <!-- Icon menu -->
	  <a id="nav-menu">
	  	<div id="menu"></div>
	  </a>

      <!-- Header -->
      
        <header id="header" class="parent justify-spaceBetween">
  <div class="inner w100 relative">
    <span class="f-left">  
      <a href="/">
          <h1><code>()=>{}</code></h1>
      </a>
    </span>
    <span id="nav-links" class="absolute right bottom">
      <!-- Nav pages -->
      
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          <a href="/about" title="About">About</a>
      
      
        
          <a href="/architecture" title="Architecture">Architecture</a>
      
      
        
      
        
          <a href="/genai" title="GenAI">GenAI</a>
      
      
        
          <a href="/cbm" title="8bits">8bits</a>
      
      
        
          <a href="/sh" title="IoT">IoT</a>
      
      
        
          <a href="/privacy" title="Privacy">Privacy</a>
      
      
      
      <!-- Nav links -->
      <a href="https://github.com/maciejmalecki">Github</a>


    </span>
  </div>
</header>




      

    <!-- Main content -->
	  <div id="container">

		<main>

			<article id="post-page">
	<h2>The Rise of Vibe Coding</h2>		
	<time datetime="2025-08-23T00:00:00+00:00" class="by-line">23 Aug 2025</time>
	<div class="disclaimer">
		The views and opinions expressed in this blog are solely my own and do not reflect the views, policies, or positions of my employer or any professional organization with which I am affiliated.
	</div>
	<div class="content">

		<p>With <em>Vibe Coding</em> it’s the same as with <em>Agile</em>: a reasonable idea gets ruined by misunderstanding, and this gets worse as the hype continues. This may happen if an idea is applied blindly, or even forcibly, and the result is far from what was anticipated. Losses instead of profits, and so on. Is it still not too late?</p>

<p>First, let’s try to understand what <em>Vibe Coding</em> really is. We can find an informal definition on <a href="https://en.wikipedia.org/wiki/Vibe_coding">Wikipedia</a>. By Vibe Coding, we mean a completely different approach to coding: a chatbot-based approach rather than an assistant-based one. The developer no longer works with the code directly, but rather develops via a series of prompts, letting the GenAI agent provide the implementation. The developer focuses on problem definition, testing, and providing feedback, also via prompts. Looking at the simplified coding assistant anatomy diagram below, we can see that the agent mode (the heart of Vibe Coding) is the most sophisticated and autonomous component on the right, finally capable of comprehending written software as a whole.</p>

<p><img src="/genai/img/anatomy-of-coding-assistant.excalidraw.png" alt="Anatomy" />
<em>Anatomy of AI coding assistant, based on GitHub Copilot.</em></p>

<p>According to the aforementioned definition, the following points characterise Vibe Coding:</p>

<ol>
  <li>The developer no longer micromanages the code.</li>
  <li>The developer accepts the generated code without fully understanding it.</li>
  <li>The developer tests the generated code at runtime. If there is any misbehaviour, the developer uses further prompts to ask the AI to fix the problem.</li>
</ol>

<p>The apparent consequence of this approach is that it is no longer necessary to have programming knowledge or to understand the details of frameworks or libraries in order to model data or algorithms properly. In other words, software engineering skills are no longer necessary to write an application.</p>

<p>As I have previously suggested in <a href="significance-of-architecture">another article</a>, uncontrolled code generation without properly established architectural restrictions may lead to rapid quality degradation and exponential growth in complexity, consequently resulting in the technical death of the code base. This is, of course, something that I cannot yet prove.</p>

<p>So, with this vague definition and an enormous wave of hype surrounding everything related to generative AI, we are clearly on the path to trivialising yet another IT term: <em>vibe coding</em>!</p>

<h2 id="the-experiment">The Experiment</h2>

<p>In my free time, I do some assembly coding for an outdated machine called the Commodore 64, which premiered around 1982. To make my life easier, I have incorporated modern tools such as cross assemblers and CI/CD pipelines.</p>

<p><img src="/cbm/img/commodore64.jpg" alt="Commodore 64" />
<em>That’s a Commodore 64 — I’ve owned one since 1990. The blurry badge proudly reads: ‘Personal Computer’.</em></p>

<p>The majority of my GitHub repositories are MOS 6502 assembly projects, except for one called <a href="https://c64lib.github.io/gradle-retro-assembler-plugin/">Retro Build Tool</a> (RBT), which is essentially a Gradle build system plugin implemented in the Kotlin language. RBT is simply a Gradle plugin that knows how to build assembly projects for Commodore 64.</p>

<p>RBT is not a large project; it currently comprises around 13,000 lines of code, but its complexity means it is not straightforward. It is comparable to the typical microservice. If vibe coding works for this project, it should be useful for real-life microservice-based codebases. However, if it fails, it cannot be used as a reliable development method for the majority of existing software.</p>

<p>One problem I have noticed while working with RBT is that, although it offers a seamless experience with simple, straightforward “one-pass” assembly projects, it struggles with more complex work. For example, when I started working on <a href="https://monochrome-productions.itch.io/tony">Tony: Montezuma’s Gold</a> and moved beyond the one-file demo version, I discovered that RBT now needs to support a multi-module, multi-part project with two compilation targets: a 5.25” floppy disk and a ROM cartridge in Magic Desk format. I had to include packing, as the assets were really big, as well as a kind of linking: an intermediate compilation step followed by additional compression, and then another compilation to the desired format (disk image/ROM image).</p>

<p>I was able to do this within Gradle using a lot of custom ad hoc tasks and CLI commands, but the result was rather messy. Another problem was that the execution was sequential and took a long time. This is because I know very little about the Gradle API; the documentation is rather cryptic, and this is a project in my free time. Apparently, free time is not enough in my case! I know Gradle can track file changes and run only the necessary tasks, and it can even parallelise tasks, but I had no idea how to write a plugin that uses all these features.</p>

<p>So, I created some entries in my backlog and left them for the next six months. This is a very good topic to start playing with agent and vibe coding, isn’t it?</p>

<h2 id="how-do-i-work">How do I work?</h2>

<p>I choose GitHub Copilot as a plugin into IntelliJ Ultimate IDE. The tool, as for now, supports code completion (via CODEX model), chat and edits function and, of course, an agent mode.</p>

<p>Agent mode supports following models without limitations (included in the license):</p>
<ol>
  <li>GPT-4o</li>
  <li>GPT-4.1</li>
</ol>

<p>Additionally, following premium models are available:</p>
<ol>
  <li>Claude Sonnet 3.5</li>
  <li>Claude Sonnet 3.7</li>
  <li>Claude Sonnet 4</li>
  <li>Gemini 2.5 Pro</li>
  <li>o4-mini (preview)</li>
</ol>

<p>The Gemini and o4 models were in preview, but I noticed today that the Gemini model is now GA. The premium models have limits; all but the o4-mini cost the same (1x tariff), while the o4-mini is much cheaper (0.33x tariff).</p>

<p>GitHub Copilot also supports an instructions file in Markdown format that can be stored in the project repository and shared across the team. However, I don’t have a team.</p>

<p>I prefer a careful approach and don’t accept much risk; therefore, I gave up on naive usage of the agent. I know that the agent mode (as well as other coding agents) is implemented internally as a <a href="https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/#planning-step">“plan and execute”</a> agent, so I have configured my Copilot to externalise the plan into a file that I store in my project repository and use in subsequent iterations of my work with the agent.</p>

<p>So, my work basically requires three kinds of prompts:</p>

<ol>
  <li><strong>User story prompt</strong> specifying the feature that needs to be implemented that results in planning the work and storing the action plan in separate MD file.</li>
  <li><strong>Execution prompt</strong> asking to execute certain points from the action plan.</li>
  <li><strong>Enhancing the plan prompt</strong> asking to extend existing plan with new facts, decisions and points.</li>
</ol>

<p>It would be tedious to orchestrate the agent so that it does exactly what I want (planning, execution, enhancement, updating the plan document, etc.), therefore I use the copilot instructions file as a kind of system prompt. Let’s take a look at my instructions file.</p>

<blockquote>
  <h1 id="coding-guidelines">Coding guidelines</h1>
  <p>…a place to put your specific guidelines, 
including architecture guidelines…</p>

  <h1 id="testing-guidelines">Testing guidelines</h1>
  <p>…a place to put some more details on how 
test automation is done…</p>

  <h1 id="general-notes-on-working-approach-relevant-for-agent-mode">General notes on working approach relevant for Agent mode</h1>
  <h2 id="tools">Tools</h2>
  <ol>
    <li>We use Powershell so always use syntax of powershell when running commands. In p articular do not use <code class="language-plaintext highlighter-rouge">&amp;&amp;</code>.</li>
    <li>Use <code class="language-plaintext highlighter-rouge">gradle build</code> to quickly compile the client code</li>
    <li>Use <code class="language-plaintext highlighter-rouge">gradle test</code> to run all tests in the client code</li>
    <li>use <code class="language-plaintext highlighter-rouge">gradle spotlessApply</code> to format the code according to the coding style</li>
    <li>always run <code class="language-plaintext highlighter-rouge">gradle spotlessApply</code> after creating or editing any source files to ensure the code is formatted correctly</li>
  </ol>

  <h2 id="prepare-plan">Prepare plan</h2>
  <p>Always use this approach when user asks in agent mode to create an action plan. At the beginning of each task, prepare a plan for the task. If not specified in the user prompt explicitly, ask user for a feature name to name the plan MD file accordingly.</p>

  <ol>
    <li>Identify Relevant Codebase Parts: Based on the issue description and project onboarding document, determine  which parts of the codebase are most likely connected to this issue. List and number specific parts of the  codebase mentioned in both documents. Explain your  reasoning for each.</li>
    <li>Hypothesize Root Cause: Based on the information gathered, list potential causes for the issue. Then, choose the most likely cause and explain your reasoning.</li>
    <li>Identify Potential Contacts: List names or roles mentioned in the documents that might be helpful to contact for assistance with this issue. For each contact, explain why they would be valuable to consult.</li>
    <li>Self-Reflection Questions: Generate a list of questions that should be asked to further investigate and understand the issue. Include both self-reflective questions and  questions for others. Number each question as you write it.</li>
    <li>Next Steps: Outline the next steps for addressing this issue, including specific actions for logging, debugging and documenting. Provide a clear, actionable plan. Number each step and provide a brief rationale for why it’s necessary.</li>
  </ol>

  <p>After completing your analysis, create a Markdown document with the following structure:</p>
  <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh"># Action Plan for [Issue Name]</span>

<span class="gu">## Issue Description</span>
[Briefly summarize the issue]

<span class="gu">## Relevant Codebase Parts</span>
[List and briefly describe the relevant parts of the codebase]

<span class="gu">## Root Cause Hypothesis</span>
[State and explain your hypothesis]

<span class="gu">## Investigation Questions</span>
[List self-reflection questions and questions for others]

<span class="gu">## Next Steps</span>
[Provide a numbered list of actionable steps, including logging and debugging tasks]

<span class="gu">## Additional Notes</span>
[Any other relevant information or considerations]
</code></pre></div>  </div>

  <p>Ensure that your action plan is comprehensive, follows a step-by-step approach, and is presented in an easy-to-read Markdown format. The final document should be named .ai/feature-{feature name}-action-plan.md</p>

  <h2 id="execute-plan">Execute plan</h2>
  <ol>
    <li>When developer asks for executing plan step, it is always meant to be a step from the <em>next steps</em> section of the action plan.</li>
    <li>When developer asks for complete plan execution, execute the plan step by step but stop and ask for confirmation before executing each step</li>
    <li>When developer asks for single step execution, execute only that step</li>
    <li>When developer asks additionally for some changes, update existing plan with the changes being made</li>
    <li>Once finishing executing of the step, always mark the step as completed in the action plan by adding a ✅ right before step name.</li>
    <li>Once finishing executing the whole phase, always mark the phase as completed in the action plan by adding a ✅ right before phase name.</li>
    <li>If by any reason the step is skipped, it should be marked as skipped in the action plan by adding a ⏭️ right before step name. It should be clearly stated why it was skipped.</li>
    <li>Always update action plan with relevant findings during plan execution, such as new questions, new contacts, new codebase parts, etc.</li>
  </ol>
</blockquote>

<p><em>Get current version of “copilot-instructions” file <a href="https://github.com/c64lib/gradle-retro-assembler-plugin/blob/develop/.github/copilot-instructions.md">here</a>.</em></p>

<p>As you can see, you can include a lot of useful information in the instructions file, but bear in mind the LLM limits and aim to be brief and concise. The key information is included in the <strong>General notes on working approach relevant for Agent mode</strong> section.</p>

<ul>
  <li>In the <strong>Tools</strong> subsection, I explain how to use the useful tools available for the project. That’s right — my Gradle plugin project uses Gradle as a build tool itself, and the build file contains everything the agent needs to work and verify the results.</li>
  <li>In the <strong>Prepare plan</strong> subsection, I explain exactly how the plan should be created and what its structure should be. This is a kind of ‘one-shot’ prompting technique that deliberately covers the <strong>user story prompt</strong> (see above).</li>
  <li>In the <strong>Execute plan</strong> subsection, I explain exactly how the agent should execute the plan, which covers both the <strong>Execution prompt</strong> and the <strong>Enhancing the plan prompt</strong> (also mentioned above).</li>
</ul>

<h2 id="sample-prompts">Sample prompts</h2>

<p>Having completed all the preparations described above, I can start vibe coding simply by selecting Agent Mode in the Copilot plugin and entering a prompt that describes the problem.</p>

<blockquote>
  <p>Currently, all tasks in the project are executed sequentially, not leveraging parallelization feature of Gradle. This results in very long build times for complex projects that execute compilation, preprocessing and postprocessing of long projects. Propose a new bounded context named ‘flows’ that will allow to organize tasks into chains (flows) that can depend on each other (outputs of one flow can feed input of another flows). This new flow mechanism should have a separate, new DSL syntax. Create an action plan.</p>
</blockquote>

<p>Using Claude’s Sonnet 4 as a model, I came up with the following action plan:</p>

<blockquote>
  <h1 id="action-plan-for-flows-parallelization-enhancement">Action Plan for Flows Parallelization Enhancement</h1>

  <h2 id="issue-description">Issue Description</h2>
  <p>Currently, all tasks in the Retro Assembler Plugin are executed sequentially, not leveraging Gradle’s parallelization features. This results in very long build times for complex projects that execute compilation,  preprocessing, and postprocessing. The existing <code class="language-plaintext highlighter-rouge">flows</code>  bounded context exists but lacks implementation. We need to enhance it with a new DSL syntax that allows organizing tasks into chains (flows) that can depend on  each other, where outputs of one flow can feed inputs of  another flows, enabling parallel execution.</p>

  <h2 id="relevant-codebase-parts">Relevant Codebase Parts</h2>
  <ol>
    <li><strong>flows/</strong> - Empty bounded context directory that needs to be populated with domain logic and adapters</li>
    <li><strong>infra/gradle/src/main/kotlin/com/github/c64lib/gradle/RetroAssemblerPlugin.kt</strong>
      <ul>
        <li>Main plugin where tasks are currently registered sequentially</li>
      </ul>
    </li>
    <li><strong>shared/gradle//</strong> - Contains existing DSL extensions and task utilities that need to be enhanced</li>
    <li><strong>compilers/kickass//</strong> - Kick Assembler integration that represents the main compilation flow</li>
    <li><strong>processors//</strong> - Various processor modules (charpad, goattracker, image, spritepad) that can be parallelized</li>
    <li><strong>dependencies//</strong> - Dependency resolution that can run in parallel with other tasks</li>
    <li><strong>emulators/vice//</strong> - Testing execution that depends on compilation outputs</li>
    <li><strong>buildSrc//</strong> - Contains Gradle plugin definitions that need enhancement for flow support</li>
  </ol>

  <h2 id="root-cause-hypothesis">Root Cause Hypothesis</h2>
  <p>The current architecture treats each task as an independent Gradle task with simple dependencies, but doesn’t leverage Gradle’s built-in parallelization capabilities. The missing piece is:</p>
  <ol>
    <li><strong>Flow Definition DSL</strong> - A way to define task chains with explicit input/output relationships</li>
    <li><strong>Dependency Graph Analysis</strong> - Logic to analyze which flows can run in parallel</li>
    <li><strong>Task Orchestration</strong> - Enhanced task registration that respects parallel execution capabilities</li>
    <li><strong>Resource Management</strong> - Proper handling of shared resources and output artifacts</li>
  </ol>

  <h2 id="investigation-questions">Investigation Questions</h2>
  <ol>
    <li>What are the current bottlenecks in build execution time?</li>
    <li>Which tasks are independent and can run in parallel (e.g., different processors)?</li>
    <li>What are the input/output dependencies between different task types?</li>
    <li>How should the new DSL syntax look to be intuitive for users?</li>
    <li>What Gradle features should we leverage for parallel execution?</li>
    <li>How do we maintain backward compatibility with existing build scripts?</li>
    <li>What validation is needed to prevent circular dependencies in flows?</li>
    <li>How do we handle error propagation in parallel flows?</li>
    <li>What monitoring/logging is needed for parallel execution debugging?</li>
    <li>How do we test the parallel execution scenarios effectively?</li>
  </ol>

  <h2 id="next-steps">Next Steps</h2>

  <h3 id="phase-1-domain-model-design-steps-1-3">Phase 1: Domain Model Design (Steps 1-3)</h3>
  <ol>
    <li><strong>Design Flow Domain Model</strong> - Create core domain entities for Flow, FlowStep, FlowDependency, and FlowExecutor in the flows domain
      <ul>
        <li>Rationale: Establishes the foundational business logic for flow management</li>
      </ul>
    </li>
    <li><strong>Define Flow DSL Syntax</strong> - Design the Kotlin DSL syntax for defining flows in build.gradle.kts files
      <ul>
        <li>Rationale: Users need an intuitive way to define 
parallel execution flows</li>
      </ul>
    </li>
    <li><strong>Create Flow Dependency Graph</strong> - Implement logic to build and validate dependency graphs between flows
      <ul>
        <li>Rationale: Essential for determining which flows can    execute in parallel</li>
      </ul>
    </li>
  </ol>

  <h3 id="phase-2-core-implementation-steps-4-7">Phase 2: Core Implementation (Steps 4-7)</h3>
  <ol>
    <li><strong>Implement Flow Domain Layer</strong> - Build the core business logic for flow execution and dependency management
      <ul>
        <li>Rationale: Contains the parallelization logic independent of Gradle specifics</li>
      </ul>
    </li>
    <li><strong>Create Gradle Adapter Layer</strong> - Build adapters that integrate flow domain with Gradle’s task system
      <ul>
        <li>Rationale: Bridges domain logic with Gradle’s parallel execution capabilities</li>
      </ul>
    </li>
    <li><strong>Enhance Plugin Registration</strong> - Update 
RetroAssemblerPlugin to register flows instead of individual tasks
      <ul>
        <li>Rationale: Enables the plugin to orchestrate parallel execution</li>
      </ul>
    </li>
    <li><strong>Implement Flow DSL Extension</strong> - Create Gradle extensions that provide the flow DSL to build scripts
      <ul>
        <li>Rationale: Provides user-facing API for defining flows</li>
      </ul>
    </li>
  </ol>

  <h3 id="phase-3-integration-and-testing-steps-8-10">Phase 3: Integration and Testing (Steps 8-10)</h3>
  <ol>
    <li><strong>Create Integration Tests</strong> - Build comprehensive tests for parallel flow execution scenarios
      <ul>
        <li>Rationale: Ensures parallel execution works correctly and safely</li>
      </ul>
    </li>
    <li><strong>Update Existing Task Implementations</strong> - Migrate existing processors and compilers to use flow system
      <ul>
        <li>Rationale: Leverages new parallelization for existing  functionality</li>
      </ul>
    </li>
    <li><strong>Performance Benchmarking</strong> - Implement benchmarks to measure parallelization improvements
      <ul>
        <li>Rationale: Validates that the changes actually improve build performance</li>
      </ul>
    </li>
  </ol>

  <h3 id="phase-4-documentation-and-release-steps-11-13">Phase 4: Documentation and Release (Steps 11-13)</h3>
  <ol>
    <li><strong>Update Documentation</strong> - Enhance AsciiDoctor documentation with flow DSL examples and migration guide
      <ul>
        <li>Rationale: Users need clear guidance on using the new parallelization features</li>
      </ul>
    </li>
    <li><strong>Update CHANGES.adoc</strong> - Document the new flow parallelization feature and breaking changes
      <ul>
        <li>Rationale: Maintains project change log as per guidelines</li>
      </ul>
    </li>
    <li><strong>Create Migration Examples</strong> - Build example projects showing before/after flow definitions
      <ul>
        <li>Rationale: Helps users adopt the new parallelization features</li>
      </ul>
    </li>
  </ol>

  <h3 id="phase-5-advanced-features-steps-14-15">Phase 5: Advanced Features (Steps 14-15)</h3>
  <ol>
    <li><strong>Implement Flow Monitoring</strong> - Add logging and metrics for parallel execution debugging
      <ul>
        <li>Rationale: Essential for troubleshooting parallel execution issues</li>
      </ul>
    </li>
    <li><strong>Add Flow Validation</strong> - Implement compile-time validation for flow definitions and dependencies
      <ul>
        <li>Rationale: Prevents runtime errors from misconfigured flows</li>
      </ul>
    </li>
  </ol>

  <h2 id="additional-notes">Additional Notes</h2>
  <ul>
    <li><strong>Backward Compatibility</strong>: The implementation should maintain compatibility with existing build scripts while providing migration path to flows</li>
    <li><strong>Error Handling</strong>: Parallel execution requires robust error handling and propagation mechanisms</li>
    <li><strong>Resource Contention</strong>: Consider file system and memory resource management for parallel tasks</li>
    <li><strong>Testing Strategy</strong>: Focus on BDD-style tests using Kotest’s Given/When/Then DSL as per project guidelines</li>
    <li><strong>Gradle Integration</strong>: Leverage Gradle’s built-in parallel execution features rather than implementing custom threading</li>
    <li><strong>Performance Monitoring</strong>: Include metrics collection to validate performance improvements and identify bottlenecks</li>
  </ul>
</blockquote>

<p><em>Get latest version of this action plan <a href="https://github.com/c64lib/gradle-retro-assembler-plugin/blob/develop/.ai/62-pipelines/feature-flows-parallelization-action-plan.md">here</a>.</em></p>

<p>I received a very detailed plan consisting of 15 steps, which were divided into five phases. I received an identification of potentially relevant files and resources. I have a root cause hypothesis describing why I need this feature and why the current implementation is not good enough for me. Finally, I have a set of reflective questions showing how broad the context and scope of thinking for the selected model is.</p>

<p>I can review this plan at any time, manually correct it if necessary, and then use it as an attachment to any interaction with the agent. Even if I exceed the token window, I can create a new conversation, put the plan into context, and continue with a much smaller penalty than if the agent had to plan the work from scratch.</p>

<h2 id="preliminary-conclusions">Preliminary conclusions</h2>

<p>I have successfully implememented three features using this technique:</p>

<ol>
  <li>I have prototyped flow DSL and created placeholders for all types of flow steps that I would need.</li>
  <li>I have implemented assemble step and integrate it with existing <a href="https://theweb.dk/KickAssembler/Main.html#frontpage">Kick Assembler task</a>.</li>
  <li>I have implemented CLI step allowing to execute arbitrary CLI command in the flow.</li>
</ol>

<p>I have tested the generated code and confirmed that it already supports file sensing and differential builds. However, it still does not use parallelisation.</p>

<p>I was able to recover from at least 80% of problems with code generated by the agent via further prompting, either directly in the conversation or, in more complex cases, by enhancing the existing action plan and executing the newly added steps. Occasionally, I had to type ‘continue’ because the agent exceeded its tool execution limits. On only two or three occasions did I need to manually fix the code, although the agent would most likely have been able to fix this problem itself. The only time I had to give up and discard all changes was when I tried to rely on GPT models only.</p>

<p>Nevertheless, it is advisable to commit to Git frequently, after each iteration, because the agent sometimes performs erratic actions, such as erasing the entire contents of the action plan.</p>

<p>I spent around 12 hours coding with the agent and used about 25% of my monthly premium token quota (yes!). That’s a lot, but I mostly used the Claude Sonnet 4 premium model.</p>

<h3 id="a-rant-on-models">A rant on models</h3>

<p>Once I discovered how quickly premium credits get consumed, I tried different models.</p>

<p><img src="/genai/img/abby-normal.jpg" alt="Abby Normal" />
<em>- What kind of model did you choose? - Abby. - Abby what? - Abby Normal!</em></p>

<p>I always started with any of Claude Sonnet models, but after a while I decided to use version 4, as it seemed to be the fastest. I strongly prefer Claude for planning purposes.</p>

<p>The Gemini model usually failed to execute, but that was when it was still in the ‘preview’ phase.</p>

<p>I fell back to GPT models and was appalled by their performance, especially that of GPT-4o. Both models have a very limited token window, require frequent restarts and have significant issues with tool usage and output capture. GPT models were also prone to hallucinations.</p>

<p><img src="/genai/img/hackman-to-use-tools.jpg" alt="Tools" />
<em>A LLM prepares to use a tool, properly.</em></p>

<p>Other than Claude, the only model capable of executing the plan with good results is o4-mini, although it can be very slow (it’s still in preview). o4 seems to be a good choice, especially since it costs only 30% of a Claude model.</p>

<p>I have had some positive experiences with GPT-4.1, including creating plans with that model. However, it still requires a lot of work on my system prompt to be fully useful.</p>

<blockquote>
  <p><strong>Hypothesis:</strong>
<em>GPT-4.1</em> is an economical approach for simple tasks, <em>Claude Sonnet 4</em> + <em>o4-mini</em> are best combination for most complex tasks. If you can afford, use <em>Claude Sonnet 4</em> solely.</p>
</blockquote>

<p>So my current ranking of models is:</p>

<ol>
  <li>Claude Sonnet 4 (3.7, 3.5) - best</li>
  <li>o4-mini (preview) - ok</li>
  <li>GPT-4.1 - acceptable for simple tasks</li>
  <li>GPT-4o - don’t use it</li>
  <li>Gemini 2.5 Pro - no idea, preview version usually didn’t work</li>
</ol>

<h3 id="a-rant-on-the-future">A rant on the future</h3>

<p><strong>If you are a software developer, please read this carefully.</strong> Of course, I cannot see the future, and this is just my opinion, but I think that:</p>

<ol>
  <li>Knowledge of multiple programming languages is no longer advantageous. With the AI Agent, it is sufficient to know a single language well, and to understand programming paradigms rather than concrete syntax. I know Java very well, but only a little Kotlin, despite my project being in Kotlin.</li>
  <li>Knowledge of multiple frameworks is irrelevant. You need to understand the concepts (e.g. SPA, IoC) and let AI handle the specifics. I don’t understand the Gradle API well enough, but AI fills that gap.</li>
  <li>Knowledge of algorithms is no longer essential, but you need to understand complexity if you care about performance or resources. You need to know how to instruct AI in this respect.</li>
  <li>Forget about knowledge of libraries — as long as it’s mainstream, AI will do it for you.</li>
</ol>

<p>If you are an IT interviewer, consider points 1-4 and rethink the questions you used to ask.</p>

<p><strong>What do you need to know?</strong></p>

<ol>
  <li>You need to know how to define the problem using natural language. In other words, you need to possess some domain and business analysis skills.</li>
  <li>You need to know how to define and protect the architecture. As I wrote <a href="significance-of-architecture">here</a>, I don’t believe that architecture has lost its significance.</li>
  <li>You need to be ready to jump in. At the current stage of tool maturity, this means you need to be able to understand the generated code well enough to fix it manually.</li>
</ol>

<p>To me, it seems that the AI Agent still rewards seniority. We are not yet at the stage where engineering skills can be completely eliminated from software development. As always, and especially on commercial projects, it is highly advisable to proceed with caution. Perhaps in the future one will see the “plan and execute” technique as “prompt overengineering”, but for now it’s still useful to understand how it works.</p>

<p>In subsequent articles, I will describe my journey in detail. I will share more prompts, action plans, and complete Git branches with all the Vibe coding history.</p>


		
	</div>
</article>



	  </main>

		  <!-- Pagination links -->
      

	  </div>

	    <!-- Footer -->
	    <footer><span>&#169; 2018-2025 Maciej Małecki &#10540; last update: 2025-08-25 16:55</span></footer>


      <div id="gdpr" style="display: none;">
        <p>
          This web page uses cookies to track anonymous user activities. By continuing using this site
          or by closing this banner you indicate your consent to use these cookies.
          You can change settings, i.e. disable user tracking on <a href="privacy.html">privacy</a> page.
        </p>
        <button id="gdprClose">Close</button>
      </div>

	    <!-- Script -->
      <script src="/js/main.js"></script>	


	</div>

</body>
</html>
