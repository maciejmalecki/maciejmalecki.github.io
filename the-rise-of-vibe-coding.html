<!DOCTYPE html>
<html>

<head>
	
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-8E02V5EDF9"></script>
	<script>
		var useCookies = (localStorage.getItem('useCookies') === 'true');
		if (useCookies) {
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());
			gtag('config', 'G-8E02V5EDF9', { 'anonymize_ip': true });
		}
	</script>
	

	<!-- Meta -->
	<meta charset="UTF-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
	<meta name="generator" content="Jekyll">

	<title>The Rise of Vibe Coding</title>
  <meta name="description" content="t.b.d.">

	<!-- CSS & fonts -->
	<link rel="stylesheet" href="/css/main.css">

	<!-- RSS -->
	<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="ATOM Feed" />

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/png" href="img/favicon.png">

</head>


<body>
	<div id="wrap">

	  	<!-- Navigation -->
	  	<nav id="nav">
	<div id="nav-list">
		<a href="//">Home</a>

		<!-- Nav pages -->
	  
	    
	  
	    
	      <a href="/about" title="About">About</a>
	    
	  
	    
	      <a href="/architecture" title="Architecture">Architecture</a>
	    
	  
	    
	      <a href="/asm" title="Assembly language">Assembly language</a>
	    
	  
	    
	  
	    
	      <a href="/cbm" title="8bits">8bits</a>
	    
	  
	    
	      <a href="/genai" title="GenAI">GenAI</a>
	    
	  
	    
	  
	    
	  
	    
	      <a href="/privacy" title="Privacy">Privacy</a>
	    
	  
	    
	      <a href="/sh" title="IoT">IoT</a>
	    
	  
	    
	  
	    
	  
	    
	  
    
    <!-- Nav links -->
	  <a href="https://github.com/maciejmalecki">Github</a>


	</div>
  
  <!-- Nav footer -->
	
	  <footer>
	
	<span>version 1.0.0</span>

</footer>
	

</nav>


    <!-- Icon menu -->
	  <a id="nav-menu">
	  	<div id="menu"></div>
	  </a>

      <!-- Header -->
      
        <header id="header" class="parent justify-spaceBetween">
  <div class="inner w100 relative">
    <span class="f-left">  
      <a href="/">
          <h1><code>()=>{}</code></h1>
      </a>
    </span>
    <span id="nav-links" class="absolute right bottom">
      <!-- Nav pages -->
      
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          <a href="/about" title="About">About</a>
      
      
        
          <a href="/architecture" title="Architecture">Architecture</a>
      
      
        
      
        
          <a href="/genai" title="GenAI">GenAI</a>
      
      
        
          <a href="/cbm" title="8bits">8bits</a>
      
      
        
          <a href="/sh" title="IoT">IoT</a>
      
      
        
          <a href="/privacy" title="Privacy">Privacy</a>
      
      
      
      <!-- Nav links -->
      <a href="https://github.com/maciejmalecki">Github</a>


    </span>
  </div>
</header>




      

    <!-- Main content -->
	  <div id="container">

		<main>

			<article id="post-page">
	<h2>The Rise of Vibe Coding</h2>		
	<time datetime="2025-08-23T00:00:00+00:00" class="by-line">23 Aug 2025</time>
	<div class="disclaimer">
		The views and opinions expressed in this blog are solely my own and do not reflect the views, policies, or positions of my employer or any professional organization with which I am affiliated.
	</div>
	<div class="content">

		<p>With <em>Vibe Coding</em> it’s the same as with <em>Agile</em>: a reasonable idea gets ruined by misunderstanding, and this gets worse as the hype continues. This may happen if an idea is applied blindly, or even forcibly, and the result is far from what was anticipated. Losses instead of profits, and so on. Is it still not too late?</p>

<p>First, let’s try to understand what <em>Vibe Coding</em> really is. We can find an informal definition on <a href="https://en.wikipedia.org/wiki/Vibe_coding">Wikipedia</a>. By Vibe Coding, we mean a completely different approach to coding: a chatbot-based approach rather than an assistant-based one. The developer no longer works with the code directly, but rather develops via a series of prompts, letting the GenAI agent provide the implementation. The developer focuses on problem definition, testing, and providing feedback, also via prompts. Looking at the simplified coding assistant anatomy diagram below, we can see that the agent mode (the heart of Vibe Coding) is the most sophisticated and autonomous component on the right, finally capable of comprehending written software as a whole.</p>

<p><img src="/genai/img/anatomy-of-coding-assistant.excalidraw.png" alt="Anatomy" />
<em>Anatomy of AI coding assistant, based on GitHub Copilot.</em></p>

<p>According to the aforementioned definition, the following points characterise Vibe Coding:</p>

<ol>
  <li>The developer no longer micromanages the code.</li>
  <li>The developer accepts the generated code without fully understanding it.</li>
  <li>The developer tests the generated code at runtime. If there is any misbehaviour, the developer uses further prompts to ask the AI to fix the problem.</li>
</ol>

<p>The apparent consequence of this approach is that it is no longer necessary to have programming knowledge or to understand the details of frameworks or libraries in order to model data or algorithms properly. In other words, software engineering skills are no longer necessary to write an application.</p>

<p>As I have previously suggested in <a href="significance-of-architecture">another article</a>, uncontrolled code generation without properly established architectural restrictions may lead to rapid quality degradation and exponential growth in complexity, consequently resulting in the technical death of the code base. This is, of course, something that I cannot yet prove.</p>

<p>So, with this vague definition and an enormous wave of hype surrounding everything related to generative AI, we are clearly on the path to trivialising yet another IT term: <em>vibe coding</em>!</p>

<h2 id="the-experiment">The Experiment</h2>

<p>In my free time, I do some assembly coding for an outdated machine called the Commodore 64, which premiered around 1982. To make my life easier, I have incorporated modern tools such as cross assemblers and CI/CD pipelines.</p>

<p><img src="/cbm/img/commodore64.jpg" alt="Commodore 64" />
<em>That’s a Commodore 64 — I’ve owned one since 1990. The blurry badge proudly reads: ‘Personal Computer’.</em></p>

<p>The majority of my GitHub repositories are MOS 6502 assembly projects, except for one called <a href="rbt-home-page">Retro Build Tool</a> (RBT), which is essentially a Gradle build system plugin implemented in the Kotlin language. RBT is simply a Gradle plugin that knows how to build assembly projects for Commodore 64.</p>

<p>RBT is not a large project; it currently comprises around 13,000 lines of code, but its complexity means it is not straightforward. It is comparable to the typical microservice. If vibe coding works for this project, it should be useful for real-life microservice-based codebases. However, if it fails, it cannot be used as a reliable development method for the majority of existing software.</p>

<p>One problem I have noticed while working with RBT is that, although it offers a seamless experience with simple, straightforward “one-pass” assembly projects, it struggles with more complex work. For example, when I started working on <a href="https://monochrome-productions.itch.io/tony">Tony: Montezuma’s Gold</a> and moved beyond the one-file demo version, I discovered that RBT now needs to support a multi-module, multi-part project with two compilation targets: a 5.25” floppy disk and a ROM cartridge in Magic Desk format. I had to include packing, as the assets were really big, as well as a kind of linking: an intermediate compilation step followed by additional compression, and then another compilation to the desired format (disk image/ROM image).</p>

<p>I was able to do this within Gradle using a lot of custom ad hoc tasks and CLI commands, but the result was rather messy. Another problem was that the execution was sequential and took a long time. This is because I know very little about the Gradle API; the documentation is rather cryptic, and this is a project in my free time. Apparently, free time is not enough in my case! I know Gradle can track file changes and run only the necessary tasks, and it can even parallelise tasks, but I had no idea how to write a plugin that uses all these features.</p>

<p>So, I created some entries in my backlog and left them for the next six months. This is a very good topic to start playing with agent and vibe coding, isn’t it?</p>

<h2 id="how-do-i-work">How do I work?</h2>

<p>I choose GitHub Copilot as a plugin into IntelliJ Ultimate IDE. The tool, as for now, supports code completion (via CODEX model), chat and edits function and, of course, an agent mode.</p>

<p>Agent mode supports following models without limitations (included in the license):</p>
<ol>
  <li>GPT-4o</li>
  <li>GPT-4.1</li>
</ol>

<p>Additionally, following premium models are available:</p>
<ol>
  <li>Claude Sonnet 3.5</li>
  <li>Claude Sonnet 3.7</li>
  <li>Claude Sonnet 4</li>
  <li>Gemini 2.5 Pro</li>
  <li>o4-mini (preview)</li>
</ol>

<p>The Gemini and o4 models were in preview, but I noticed today that the Gemini model is now GA. The premium models have limits; all but the o4-mini cost the same (1x tariff), while the o4-mini is much cheaper (0.33x tariff).</p>

<p>GitHub Copilot also supports an instructions file in Markdown format that can be stored in the project repository and shared across the team. However, I don’t have a team.</p>

<p>I prefer a careful approach and don’t accept much risk; therefore, I gave up on naive usage of the agent. I know that the agent mode (as well as other coding agents) is implemented internally as a <a href="https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/#planning-step">“plan and execute”</a> agent, so I have configured my Copilot to externalise the plan into a file that I store in my project repository and use in subsequent iterations of my work with the agent.</p>

<p>So, my work basically requires three kinds of prompts:</p>

<ol>
  <li><strong>User story prompt</strong> specifying the feature that needs to be implemented that results in planning the work and storing the action plan in separate MD file.</li>
  <li><strong>Execution prompt</strong> asking to execute certain points from the action plan.</li>
  <li><strong>Enhancing the plan prompt</strong> asking to extend existing plan with new facts, decisions and points.</li>
</ol>

<p>It would be tedious to orchestrate the agent so that it does exactly what I want (planning, execution, enhancement, updating the plan document, etc.), therefore I use the copilot instructions file as a kind of system prompt. Let’s take a look at my instructions file.</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh"># Coding guidelines</span>
...a place to put your specific guidelines, 
including architecture guidelines...

<span class="gh"># Testing guidelines</span>
...a place to put some more details on how 
test automation is done...

<span class="gh"># General notes on working approach relevant for Agent mode</span>
<span class="gu">## Tools</span>
<span class="p">1.</span> We use Powershell so always use syntax of powershell
 when running commands. In particular do not use <span class="sb">`&amp;&amp;`</span>.
<span class="p">2.</span> Use <span class="sb">`gradle build`</span> to quickly compile the client code
<span class="p">3.</span> Use <span class="sb">`gradle test`</span> to run all tests in the client code
<span class="p">4.</span> use <span class="sb">`gradle spotlessApply`</span> to format the code according
 to the coding style
<span class="p">5.</span> always run <span class="sb">`gradle spotlessApply`</span> after creating or 
editing any source files to ensure the code is formatted 
correctly

<span class="gu">## Prepare plan</span>
Always use this approach when user asks in agent mode to 
create an action plan.
At the beginning of each task, prepare a plan for the 
task. If not specified in the user prompt explicitly, ask 
user for a feature name to name the plan MD file 
accordingly.<span class="sb">


</span><span class="p">1.</span> Identify Relevant Codebase Parts: Based on the issue
 description and project onboarding document, determine 
 which parts of the codebase are most likely connected to 
 this issue. List and number specific parts of the 
 codebase mentioned in both documents. Explain your 
 reasoning for each.
<span class="p">2.</span> Hypothesize Root Cause: Based on the information 
gathered, list potential causes for the issue. Then, 
choose the most likely cause and explain your reasoning.
<span class="p">3.</span> Identify Potential Contacts: List names or roles 
mentioned in the documents that might be helpful to 
contact for assistance with this issue. For each contact, 
explain why they would be valuable to consult.
<span class="p">4.</span> Self-Reflection Questions: Generate a list of questions 
that should be asked to further investigate and understand
 the issue. Include both self-reflective questions and 
 questions for others. Number each question as you write 
 it.
<span class="p">5.</span> Next Steps: Outline the next steps for addressing this 
issue, including specific actions for logging, debugging 
and documenting. Provide a clear, actionable plan. Number 
each step and provide a brief rationale for why it's 
necessary.

After completing your analysis, create a Markdown document 
with the following structure:
<span class="sb">``markdown
# Action Plan for [Issue Name]

## Issue Description
[Briefly summarize the issue]

## Relevant Codebase Parts
[List and briefly describe the relevant parts of the codebase]

## Root Cause Hypothesis
[State and explain your hypothesis]

## Investigation Questions
[List self-reflection questions and questions for others]

## Next Steps
[Provide a numbered list of actionable steps, including logging and debugging tasks]

## Additional Notes
[Any other relevant information or considerations]
Ensure that your action plan is comprehensive, follows a 
step-by-step approach, and is presented in an easy-to-read 
Markdown format. The final document should be named .ai/
feature-{feature name}-action-plan.md
``</span>

<span class="gu">## Execute plan</span>
<span class="p">1.</span> When developer asks for executing plan step, it is 
always meant to be a step from the <span class="ge">*next steps*</span> section of 
the action plan.
<span class="p">2.</span> When developer asks for complete plan execution, 
execute the plan step by step but stop and ask for 
confirmation before executing each step
<span class="p">3.</span> When developer asks for single step execution, execute 
only that step
<span class="p">4.</span> When developer asks additionally for some changes, 
update existing plan with the changes being made
<span class="p">5.</span> Once finishing executing of the step, always mark the 
step as completed in the action plan by adding a ✅ right 
before step name.
<span class="p">6.</span> Once finishing executing the whole phase, always mark 
the phase as completed in the action plan by adding a ✅ 
right before phase name.
<span class="p">7.</span> If by any reason the step is skipped, it should be 
marked as skipped in the action plan by adding a ⏭️ right 
before step name. It should be clearly stated why it was 
skipped.
<span class="p">8.</span> Always update action plan with relevant findings during 
plan execution, such as new questions, new contacts, new 
codebase parts, etc.
</code></pre></div></div>
<p><em>Note: I don’t know how to nest Markdown in Markdown, therefore if you decide to reuse my copilot instructions, please replace two backticks (``) with three of them, to get a proper Markdown syntax.</em></p>

<p>As you can see, you can include a lot of useful information in the instructions file, but bear in mind the LLM limits and aim to be brief and concise. The key information is included in the <strong>General notes on working approach relevant for Agent mode</strong> section.</p>

<ul>
  <li>In the <strong>Tools</strong> subsection, I explain how to use the useful tools available for the project. That’s right — my Gradle plugin project uses Gradle as a build tool itself, and the build file contains everything the agent needs to work and verify the results.</li>
  <li>In the <strong>Prepare plan</strong> subsection, I explain exactly how the plan should be created and what its structure should be. This is a kind of ‘one-shot’ prompting technique that deliberately covers the <strong>user story prompt</strong> (see above).</li>
  <li>In the <strong>Execute plan</strong> subsection, I explain exactly how the agent should execute the plan, which covers both the <strong>Execution prompt</strong> and the <strong>Enhancing the plan prompt</strong> (also mentioned above).</li>
</ul>

<h2 id="sample-prompts">Sample prompts</h2>

<p>Having completed all the preparations described above, I can start vibe coding simply by selecting Agent Mode in the Copilot plugin and entering a prompt that describes the problem.</p>

<blockquote>
  <p>Currently, all tasks in the problem are executed sequentially, not leveraging parallelization feature of Gradle. This results in very long build times for complex projects that execute compilation, preprocessing and postprocessing of long projects. Propose a new bounded context named ‘flows’ that will allow to organize tasks into chains (flows) that can depend on each other (outputs of one flow can feed input of another flows). This new flow mechanism should have a separate, new DSL syntax. Create an action plan.</p>
</blockquote>

<p>Using Claude’s Sonnet 4 as a model, I came up with the following action plan:</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh"># Action Plan for Flows Parallelization Enhancement</span>

<span class="gu">## Issue Description</span>
Currently, all tasks in the Retro Assembler Plugin are 
executed sequentially, not leveraging Gradle's 
parallelization features. This results in very long build
 times for complex projects that execute compilation, 
 preprocessing, and postprocessing. The existing <span class="sb">`flows`</span> 
 bounded context exists but lacks implementation. We need 
 to enhance it with a new DSL syntax that allows 
 organizing tasks into chains (flows) that can depend on 
 each other, where outputs of one flow can feed inputs of 
 another flows, enabling parallel execution.

<span class="gu">## Relevant Codebase Parts</span>
<span class="p">1.</span> <span class="gs">**flows/**</span> - Empty bounded context directory that needs 
to be populated with domain logic and adapters
<span class="p">2.</span> <span class="gs">**infra/gradle/src/main/kotlin/com/github/c64lib/gradle/RetroAssemblerPlugin.kt**</span> 
<span class="p">-</span> Main plugin where tasks are currently registered 
sequentially
<span class="p">3.</span> <span class="gs">**shared/gradle//**</span> - Contains existing DSL extensions 
and task utilities that need to be enhanced
<span class="p">4.</span> <span class="gs">**compilers/kickass//**</span> - Kick Assembler integration 
that represents the main compilation flow
<span class="p">5.</span> <span class="gs">**processors//**</span> - Various processor modules (charpad, 
goattracker, image, spritepad) that can be parallelized
<span class="p">6.</span> <span class="gs">**dependencies//**</span> - Dependency resolution that can run in parallel with other tasks
<span class="p">7.</span> <span class="gs">**emulators/vice//**</span> - Testing execution that depends on compilation outputs
<span class="p">8.</span> <span class="gs">**buildSrc//**</span> - Contains Gradle plugin definitions that need enhancement for flow support

<span class="gu">## Root Cause Hypothesis</span>
The current architecture treats each task as an 
independent Gradle task with simple dependencies, but 
doesn't leverage Gradle's built-in parallelization 
capabilities. The missing piece is:
<span class="p">1.</span> <span class="gs">**Flow Definition DSL**</span> - A way to define task chains 
with explicit input/output relationships
<span class="p">2.</span> <span class="gs">**Dependency Graph Analysis**</span> - Logic to analyze which 
flows can run in parallel
<span class="p">3.</span> <span class="gs">**Task Orchestration**</span> - Enhanced task registration 
that respects parallel execution capabilities
<span class="p">4.</span> <span class="gs">**Resource Management**</span> - Proper handling of shared 
resources and output artifacts

<span class="gu">## Investigation Questions</span>
<span class="p">1.</span> What are the current bottlenecks in build execution 
time?
<span class="p">2.</span> Which tasks are independent and can run in parallel (e.g.
, different processors)?
<span class="p">3.</span> What are the input/output dependencies between 
different task types?
<span class="p">4.</span> How should the new DSL syntax look to be intuitive for 
users?
<span class="p">5.</span> What Gradle features should we leverage for parallel 
execution?
<span class="p">6.</span> How do we maintain backward compatibility with existing 
build scripts?
<span class="p">7.</span> What validation is needed to prevent circular 
dependencies in flows?
<span class="p">8.</span> How do we handle error propagation in parallel flows?
<span class="p">9.</span> What monitoring/logging is needed for parallel 
execution debugging?
<span class="p">10.</span> How do we test the parallel execution scenarios 
effectively?

<span class="gu">## Next Steps</span>

<span class="gu">### Phase 1: Domain Model Design (Steps 1-3)</span>
<span class="p">1.</span> <span class="gs">**Design Flow Domain Model**</span> - Create core domain 
entities for Flow, FlowStep, FlowDependency, and 
FlowExecutor in the flows domain
<span class="p">   -</span> Rationale: Establishes the foundational business 
   logic for flow management
<span class="p">
2.</span> <span class="gs">**Define Flow DSL Syntax**</span> - Design the Kotlin DSL 
syntax for defining flows in build.gradle.kts files
<span class="p">   -</span> Rationale: Users need an intuitive way to define 
   parallel execution flows
<span class="p">
3.</span> <span class="gs">**Create Flow Dependency Graph**</span> - Implement logic to 
build and validate dependency graphs between flows
<span class="p">   -</span> Rationale: Essential for determining which flows can 
   execute in parallel

<span class="gu">### Phase 2: Core Implementation (Steps 4-7)</span>
<span class="p">4.</span> <span class="gs">**Implement Flow Domain Layer**</span> - Build the core 
business logic for flow execution and dependency management
<span class="p">   -</span> Rationale: Contains the parallelization logic 
   independent of Gradle specifics
<span class="p">
5.</span> <span class="gs">**Create Gradle Adapter Layer**</span> - Build adapters that 
integrate flow domain with Gradle's task system
<span class="p">   -</span> Rationale: Bridges domain logic with Gradle's 
   parallel execution capabilities
<span class="p">
6.</span> <span class="gs">**Enhance Plugin Registration**</span> - Update 
RetroAssemblerPlugin to register flows instead of 
individual tasks
<span class="p">   -</span> Rationale: Enables the plugin to orchestrate parallel 
   execution
<span class="p">
7.</span> <span class="gs">**Implement Flow DSL Extension**</span> - Create Gradle 
extensions that provide the flow DSL to build scripts
<span class="p">   -</span> Rationale: Provides user-facing API for defining flows

<span class="gu">### Phase 3: Integration and Testing (Steps 8-10)</span>
<span class="p">8.</span> <span class="gs">**Create Integration Tests**</span> - Build comprehensive 
tests for parallel flow execution scenarios
<span class="p">   -</span> Rationale: Ensures parallel execution works correctly 
   and safely
<span class="p">
9.</span> <span class="gs">**Update Existing Task Implementations**</span> - Migrate 
existing processors and compilers to use flow system
<span class="p">   -</span> Rationale: Leverages new parallelization for existing 
   functionality
<span class="p">
10.</span> <span class="gs">**Performance Benchmarking**</span> - Implement benchmarks to 
measure parallelization improvements
<span class="p">    -</span> Rationale: Validates that the changes actually 
    improve build performance

<span class="gu">### Phase 4: Documentation and Release (Steps 11-13)</span>
<span class="p">11.</span> <span class="gs">**Update Documentation**</span> - Enhance AsciiDoctor 
documentation with flow DSL examples and migration guide
<span class="p">    -</span> Rationale: Users need clear guidance on using the 
    new parallelization features
<span class="p">
12.</span> <span class="gs">**Update CHANGES.adoc**</span> - Document the new flow 
parallelization feature and breaking changes
<span class="p">    -</span> Rationale: Maintains project change log as per 
    guidelines
<span class="p">
13.</span> <span class="gs">**Create Migration Examples**</span> - Build example projects 
showing before/after flow definitions
<span class="p">    -</span> Rationale: Helps users adopt the new parallelization 
    features

<span class="gu">### Phase 5: Advanced Features (Steps 14-15)</span>
<span class="p">14.</span> <span class="gs">**Implement Flow Monitoring**</span> - Add logging and 
metrics for parallel execution debugging
<span class="p">    -</span> Rationale: Essential for troubleshooting parallel 
    execution issues
<span class="p">
15.</span> <span class="gs">**Add Flow Validation**</span> - Implement compile-time 
validation for flow definitions and dependencies
<span class="p">    -</span> Rationale: Prevents runtime errors from 
    misconfigured flows

<span class="gu">## Additional Notes</span>
<span class="p">-</span> <span class="gs">**Backward Compatibility**</span>: The implementation should 
maintain compatibility with existing build scripts while 
providing migration path to flows
<span class="p">-</span> <span class="gs">**Error Handling**</span>: Parallel execution requires robust 
error handling and propagation mechanisms
<span class="p">-</span> <span class="gs">**Resource Contention**</span>: Consider file system and memory 
resource management for parallel tasks
<span class="p">-</span> <span class="gs">**Testing Strategy**</span>: Focus on BDD-style tests using 
Kotest's Given/When/Then DSL as per project guidelines
<span class="p">-</span> <span class="gs">**Gradle Integration**</span>: Leverage Gradle's built-in 
parallel execution features rather than implementing 
custom threading
<span class="p">-</span> <span class="gs">**Performance Monitoring**</span>: Include metrics collection 
to validate performance improvements and identify 
bottlenecks
</code></pre></div></div>

<p>I received a very detailed plan consisting of 15 steps, which were divided into five phases. I received an identification of potentially relevant files and resources. I have a root cause hypothesis describing why I need this feature and why the current implementation is not good enough for me. Finally, I have a set of reflective questions showing how broad the context and scope of thinking for the selected model is.</p>

<p>I can review this plan at any time, manually correct it if necessary, and then use it as an attachment to any interaction with the agent. Even if I exceed the token window, I can create a new conversation, put the plan into context, and continue with a much smaller penalty than if the agent had to plan the work from scratch.</p>

<h2 id="preliminary-conclusions">Preliminary conclusions</h2>

<p>I have successfully implememented three features using this technique:</p>

<ol>
  <li>I have prototyped flow DSL and created placeholders for all types of flow steps that I would need.</li>
  <li>I have implemented assemble step and integrate it with existing <a href="https://theweb.dk/KickAssembler/Main.html#frontpage">Kick Assembler task</a>.</li>
  <li>I have implemented CLI step allowing to execute arbitrary CLI command in the flow.</li>
</ol>

<p>I have tested the generated code and confirmed that it already supports file sensing and differential builds. However, it still does not use parallelisation.</p>

<p>I was able to recover from at least 80% of problems with code generated by the agent via further prompting, either directly in the conversation or, in more complex cases, by enhancing the existing action plan and executing the newly added steps. Occasionally, I had to type ‘continue’ because the agent exceeded its tool execution limits. On only two or three occasions did I need to manually fix the code, although the agent would most likely have been able to fix this problem itself. The only time I had to give up and discard all changes was when I tried to rely on GPT models only.</p>

<p>Nevertheless, it is advisable to commit to Git frequently, after each iteration, because the agent sometimes performs erratic actions, such as erasing the entire contents of the action plan.</p>

<p>I spent around 12 hours coding with the agent and used about 25% of my monthly premium token quota (yes!). That’s a lot, but I mostly used the Claude Sonnet 4 premium model.</p>

<h3 id="a-rant-on-models">A rant on models</h3>

<p>Once I discovered how quickly premium credits get consumed, I tried different models.</p>

<p><img src="/genai/img/abby-normal.jpg" alt="Abby Normal" />
<em>- What kind of model have you chose? - Abby. - Abby what? - Abby Normal!</em></p>

<p>I always started with any of Claude Sonnet models, but after a while I decided to use version 4, as it seemed to be the fastest. I strongly prefer Claude for planning purposes.</p>

<p>The Gemini model usually failed to execute, but that was when it was still in the ‘preview’ phase.</p>

<p>I fell back to GPT models and was appalled by their performance, especially that of GPT-4o. Both models have a very limited token window, require frequent restarts and have significant issues with tool usage and output capture. GPT models were also prone to hallucinations.</p>

<p><img src="/genai/img/hackman-to-use-tools.jpg" alt="Tools" />
<em>A LLM prepares to use a tool, properly.</em></p>

<p>Other than Claude, the only model capable of executing the plan with good results is o4-mini, although it can be very slow (it’s still in preview). o4 seems to be a good choice, especially since it costs only 30% of a Claude model.</p>

<p>I have had some positive experiences with GPT-4.1, including creating plans with that model. However, it still requires a lot of work on my system prompt to be fully useful.</p>

<blockquote>
  <p><strong>Hypothesis:</strong>
<em>GPT-4.1</em> is an economical approach for simple tasks, <em>Claude Sonnet 4</em> + <em>o4-mini</em> are best combination for most complex tasks. If you can afford, use <em>Claude Sonnet 4</em> solely.</p>
</blockquote>

<p>So my current ranking of models is:</p>

<ol>
  <li>Claude Sonnet 4 (3.7, 3.5) - best</li>
  <li>o4-mini (preview) - ok</li>
  <li>GPT-4.1 - acceptable for simple tasks</li>
  <li>GPT-4o - don’t use it</li>
  <li>Gemini 2.5 Pro - no idea, preview version usually didn’t work</li>
</ol>

<h3 id="a-rant-on-the-future">A rant on the future</h3>

<p><strong>If you are a software developer, please read this carefully.</strong> Of course, I cannot see the future, and this is just my opinion, but I think that:</p>

<ol>
  <li>Knowledge of multiple programming languages is no longer advantageous. With the AI Agent, it is sufficient to know a single language well, and to understand programming paradigms rather than concrete syntax. I know Java very well, but only a little Kotlin, despite my project being in Kotlin.</li>
  <li>Knowledge of multiple frameworks is irrelevant. You need to understand the concepts (e.g. SPA, IoC) and let AI handle the specifics. I don’t understand the Gradle API well enough, but AI fills that gap.</li>
  <li>Knowledge of algorithms is no longer essential, but you need to understand complexity if you care about performance or resources. You need to know how to instruct AI in this respect.</li>
  <li>Forget about knowledge of libraries — as long as it’s mainstream, AI will do it for you.</li>
</ol>

<p>If you are an IT interviewer, consider points 1-4 and rethink the questions you used to ask.</p>

<p><strong>What do you need to know?</strong></p>

<ol>
  <li>You need to know how to define the problem using natural language. In other words, you need to possess some domain and business analysis skills.</li>
  <li>You need to know how to define and protect the architecture. As I wrote <a href="significance-of-architecture">here</a>, I don’t believe that architecture has lost its significance.</li>
  <li>You need to be ready to jump in. At the current stage of tool maturity, this means you need to be able to understand the generated code well enough to fix it manually.</li>
</ol>

<p>To me, it seems that the AI Agent still rewards seniority. We are not yet at the stage where engineering skills can be completely eliminated from software development. As always, and especially on commercial projects, it is highly advisable to proceed with caution. Perhaps in the future one will see the “plan and execute” technique as “prompt overengineering”, but for now it’s still useful to understand how it works.</p>

<p>In subsequent articles, I will describe my journey in detail. I will share more prompts, action plans, and complete Git branches with all the Vibe coding history.</p>


		
	</div>
</article>



	  </main>

		  <!-- Pagination links -->
      

	  </div>

	    <!-- Footer -->
	    <footer><span>&#169; 2018-2025 Maciej Małecki &#10540; last update: 2025-08-23 20:04</span></footer>


      <div id="gdpr" style="display: none;">
        <p>
          This web page uses cookies to track anonymous user activities. By continuing using this site
          or by closing this banner you indicate your consent to use these cookies.
          You can change settings, i.e. disable user tracking on <a href="privacy.html">privacy</a> page.
        </p>
        <button id="gdprClose">Close</button>
      </div>

	    <!-- Script -->
      <script src="/js/main.js"></script>	


	</div>

</body>
</html>
